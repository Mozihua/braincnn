{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ex\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "sample_labels = [\"EMCI\", \"CN\"]\n",
    "label_to_id = {}      # key: class name\n",
    "                    # value: class id\n",
    "file_to_apoe = {}   # key: image file path\n",
    "                    # value: boolean, true if image specified 4 in either \"APOE A1\" or \"APOE A2\" fields\n",
    "\n",
    "# This is for getting ADNI files\n",
    "def get_filenames(folder, metadata_folder):\n",
    "    global label_to_id\n",
    "    for i, label in enumerate(sample_labels):\n",
    "        label_to_id[label] = i\n",
    "         \n",
    "    # Get list of images\n",
    "    image_class = {} # key: unique subject id in filename\n",
    "                     # value: image file path\n",
    "    for root, directories, filenames in os.walk(folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\"nii\") and \"__Scaled_2\" not in root:\n",
    "                identifier = filename[-11:-4]\n",
    "                image_class[identifier] = os.path.join(root,filename)\n",
    "                \n",
    "    meta_files = [f for f in os.listdir(metadata_folder) if f.endswith('xml')]\n",
    "        \n",
    "    # Label each image\n",
    "    classify_by_label = {} # key: label class in [0, 1, 2, 3]\n",
    "                           # value: list of image file paths\n",
    "    for xml in meta_files:\n",
    "        if \"__Scaled_2\" not in xml:\n",
    "            identifier = xml[-11:-4]\n",
    "            root = ex.parse(metadata_folder + \"/\" + xml).getroot()\n",
    "            classification = root[0][3][1].text\n",
    "            if classification in label_to_id:\n",
    "                cl = label_to_id[classification]\n",
    "                file_path = image_class[identifier]\n",
    "                if cl not in classify_by_label:\n",
    "                    classify_by_label[cl] = [file_path]\n",
    "                else:\n",
    "                    classify_by_label[cl].append(file_path)\n",
    "                \n",
    "                # Storing APOE e4 carrier information for each image file\n",
    "                apoe_1 = root[0][3][4].text\n",
    "                apoe_2 = root[0][3][5].text\n",
    "                \n",
    "                file_to_apoe[file_path] = False\n",
    "                if apoe_1 == \"4\" or apoe_2 == \"4\":\n",
    "                    file_to_apoe[file_path] = True\n",
    "                    \n",
    "    print(\"Statistics: {}\".format(get_stats(classify_by_label)))\n",
    "    \n",
    "    return classify_by_label\n",
    "\n",
    "def get_stats(files):\n",
    "    stats = {}\n",
    "    for k, v in files.items():\n",
    "        stats[sample_labels[int(k)]] = len(v)\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nilearn import image\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage as nd\n",
    "\n",
    "def get_files(data_folder, metadata_folder):\n",
    "    files = get_filenames(data_folder, metadata_folder)\n",
    "    return files \n",
    "\n",
    "# Size of desired image\n",
    "width = 80\n",
    "height = 80\n",
    "depth = 80\n",
    "\n",
    "def get_data(files, class_id):\n",
    "    global width, height, depth\n",
    "    num_images = len(files)\n",
    "    \n",
    "    x_data = np.zeros([num_images, height, width, depth], np.float32)\n",
    "    y_data = np.zeros(num_images, dtype=np.int32)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        loaded_img = nib.load(files[i])    \n",
    "        im = loaded_img.get_data()\n",
    "        im = nd.interpolation.zoom(im, \n",
    "                                   zoom = np.array([height, width, depth])/im.shape)\n",
    "\n",
    "        x_data[i] = np.asarray(im, dtype=np.float32)\n",
    "        y_data[i] = class_id\n",
    "    \n",
    "    x_data_ = x_data.reshape(num_images, height * width * depth)\n",
    "    return x_data_, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(num_result, class_data, class_id):\n",
    "    random_inds = random.sample(range(0, len(class_data)), num_result)\n",
    "    random_inds = sorted(random_inds, reverse=True)\n",
    "    files = []\n",
    "    for ind in random_inds:\n",
    "        files.append(class_data.pop(ind))\n",
    "    data, target = get_data(files, class_id)\n",
    "    \n",
    "    return data, target, files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics: {'EMCI': 264, 'CN': 228}\n",
      "Class EMCI. Pct APOE e4 carrier 0.5625\n",
      "Class CN. Pct APOE e4 carrier 0.5625\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# Get training data\n",
    "files = get_files('ADNI2_all/ADNI', 'ADNI2_all/metadata')\n",
    "num_samples = 0\n",
    "flattened = [[] for i in range(len(sample_labels))]\n",
    "for k, v in files.items():\n",
    "    for f in v:\n",
    "        flattened[k].append(f) \n",
    "        num_samples += 1\n",
    "\n",
    "# Store APOE e4 carrier statistics on test data\n",
    "apoe_test_files = []\n",
    "e4_carrier_stats_pre = {}\n",
    "for i in range(0, len(sample_labels)):\n",
    "    e4_carrier_stats_pre[i] = 0\n",
    "    \n",
    "num_val_samples_per_cl = 8\n",
    "num_test_samples_per_cl = 16\n",
    "\n",
    "# Split training and testing data\n",
    "tr_data = []\n",
    "tr_target = []\n",
    "val_data = []\n",
    "val_target = []\n",
    "test_data = []\n",
    "test_target = []\n",
    "for cl in range(0, len(flattened)): \n",
    "    # Get testing data\n",
    "    data, target, files = partition_data(num_test_samples_per_cl, flattened[cl], cl)\n",
    "    if len(test_data) == 0:\n",
    "        test_data = data\n",
    "        test_target = target\n",
    "    else:\n",
    "        test_data = np.append(test_data, data, axis=0)\n",
    "        test_target = np.append(test_target, target)\n",
    "                \n",
    "    # Increment values if e4 carrier status\n",
    "    apoe_test_files = np.append(apoe_test_files, files)\n",
    "    for f in files:\n",
    "        if file_to_apoe[f]:\n",
    "            e4_carrier_stats_pre[cl] += 1\n",
    "    \n",
    "    # Get validation data\n",
    "    data, target, files = partition_data(num_val_samples_per_cl, flattened[cl], cl)\n",
    "    if len(val_data) == 0:\n",
    "        val_data = data\n",
    "        val_target = target\n",
    "    else:\n",
    "        val_data = np.append(val_data, data, axis=0)\n",
    "        val_target = np.append(val_target, target)\n",
    "    \n",
    "    # Get training data\n",
    "    data, target = get_data(flattened[cl], cl)\n",
    "    if len(tr_data) == 0:\n",
    "        tr_data = data\n",
    "        tr_target = target\n",
    "    else:\n",
    "        tr_data = np.append(tr_data, data, axis=0)\n",
    "        tr_target = np.append(tr_target, target)\n",
    "    \n",
    "# Print e4 carrier stats\n",
    "for cl_id, quant in e4_carrier_stats_pre.items():\n",
    "    print(\"Class {}. Pct APOE e4 carrier {}\".format(sample_labels[cl_id], quant/num_test_samples_per_cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv3d(x, W, bias, strides=[1, 1, 1, 1, 1]):\n",
    "    conv = tf.nn.conv3d(x, W, strides, padding='SAME') \n",
    "    bias = tf.nn.bias_add(conv, bias)\n",
    "    return tf.nn.relu(bias)\n",
    "\n",
    "def batch_norm(x, training):\n",
    "    return tf.layers.batch_normalization(x, training = training)\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(shape = [None, width*height*depth],\n",
    "                   dtype = tf.float32)\n",
    "training = tf.placeholder(shape = None,\n",
    "                          dtype = tf.bool)\n",
    "\n",
    "x_image = tf.reshape(x, [-1, height, width, depth, 1])\n",
    "\n",
    "# Block 1\n",
    "W = weight([3, 3, 3, 1, 8])\n",
    "b = bias([8])\n",
    "conv1 = conv3d(x_image, W, b)\n",
    "\n",
    "W = weight([3, 3, 3, 8, 8])\n",
    "conv2 = conv3d(conv1, W, b)\n",
    "pool = max_pool_2x2(conv2)\n",
    "\n",
    "# Block 2\n",
    "W = weight([3, 3, 3, 8, 16])\n",
    "b = bias([16])\n",
    "conv3 = conv3d(pool, W, b)\n",
    "\n",
    "W = weight([3, 3, 3, 16, 16])\n",
    "conv4 = conv3d(conv3, W, b)\n",
    "pool = max_pool_2x2(conv4)\n",
    "\n",
    "# Block 3\n",
    "W = weight([3, 3, 3, 16, 32])\n",
    "b = bias([32])\n",
    "conv5 = conv3d(pool, W, b)\n",
    "\n",
    "W = weight([3, 3, 3, 32, 32])\n",
    "conv6 = conv3d(conv5, W, b)\n",
    "conv7 = conv3d(conv6, W, b)\n",
    "conv8 = conv3d(conv7, W, b)\n",
    "pool = max_pool_2x2(conv8)\n",
    "\n",
    "# Block 4\n",
    "W = weight([3, 3, 3, 32, 64])\n",
    "b = bias([64])\n",
    "conv9 = conv3d(pool, W, b)\n",
    "\n",
    "W = weight([3, 3, 3, 64, 64])\n",
    "conv10 = conv3d(conv9, W, b)\n",
    "conv11 = conv3d(conv10, W, b)\n",
    "conv12 = conv3d(conv11, W, b)\n",
    "pool = max_pool_2x2(conv12)\n",
    "\n",
    "# Block 5\n",
    "W = weight([3, 3, 3, 64, 128])\n",
    "b = bias([128])\n",
    "conv13 = conv3d(pool, W, b)\n",
    "\n",
    "W = weight([3, 3, 3, 128, 128])\n",
    "conv14 = conv3d(conv13, W, b)\n",
    "conv15 = conv3d(conv14, W, b)\n",
    "conv16 = conv3d(conv15, W, b)\n",
    "pool = max_pool_2x2(conv16)\n",
    "\n",
    "# Densely Connected Layer (or fully-connected layer)\n",
    "pool_flat = tf.layers.flatten(pool)\n",
    "fcl17 = tf.layers.dense(pool_flat, units=128, activation = tf.nn.relu)\n",
    "bn = batch_norm(fcl17, training)\n",
    "fcl18 = tf.layers.dense(bn, units=64, activation = tf.nn.relu)\n",
    "logits = tf.layers.dense(fcl18,\n",
    "                         units = len(sample_labels),\n",
    "                         activation = tf.nn.softmax)\n",
    "\n",
    "# Loss\n",
    "y_ = tf.placeholder(shape = [None],\n",
    "                    dtype = tf.int32)\n",
    "y_onehot = tf.one_hot(y_, len(sample_labels))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_onehot, \n",
    "                                                                 logits=logits))\n",
    "\n",
    "# Classification Accuracy\n",
    "predicted = tf.argmax(logits, 1)\n",
    "correct_prediction = tf.equal(predicted, tf.argmax(y_onehot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Optimizer\n",
    "opt = tf.train.AdamOptimizer(5e-6).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting variables\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_tr_acc = []\n",
    "y_tr_acc = []\n",
    "x_val_acc = []\n",
    "y_val_acc = []\n",
    "\n",
    "def plotting(train_loss, val_loss, train_acc, val_acc, final=False):\n",
    "    if final:\n",
    "        plt.figure(figsize=(20,10))\n",
    "    plt.scatter(train_loss[0], train_loss[1], color='g', s=1, label='training')\n",
    "    plt.scatter(val_loss[0], val_loss[1], color='r', s=1, label='validation')\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    if final:\n",
    "        plt.figure(figsize=(20,10))\n",
    "    plt.scatter(train_acc[0], train_acc[1], color='g', s=1, label='training')\n",
    "    plt.scatter(val_acc[0], val_acc[1], color='r', s=1, label='validation')\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,80,80,80,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv3D = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_250_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv3D', defined at:\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-54c546a2850f>\", line 14, in <module>\n    conv1 = conv3d(x_image, W, b)\n  File \"<ipython-input-5-3dab8b08c6b3>\", line 10, in conv3d\n    conv = tf.nn.conv3d(x, W, strides, padding='SAME')\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1361, in conv3d\n    name=name)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,80,80,80,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv3D = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_250_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,80,80,80,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv3D = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_250_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5046a169adf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                                           feed_dict = {x: val_data,\n\u001b[1;32m     29\u001b[0m                                                        \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                                                        training: False})\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvPred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,80,80,80,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv3D = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_250_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv3D', defined at:\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-54c546a2850f>\", line 14, in <module>\n    conv1 = conv3d(x_image, W, b)\n  File \"<ipython-input-5-3dab8b08c6b3>\", line 10, in conv3d\n    conv = tf.nn.conv3d(x, W, strides, padding='SAME')\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1361, in conv3d\n    name=name)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/carrie/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,80,80,80,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv3D = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_250_Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Params for early stopping\n",
    "patience = 16\n",
    "patience_cnt = 0\n",
    "hist_len = 50\n",
    "last_avg_loss = 0\n",
    "hist_loss = []\n",
    "min_loss_seen = None\n",
    "\n",
    "batch_size = 32\n",
    "epoch = 0\n",
    "while (patience_cnt < patience or epoch < hist_len) and epoch < 500:\n",
    "    c = list(zip(tr_data, tr_target))\n",
    "    random.shuffle(c)\n",
    "    tr_data, tr_target = zip(*c)\n",
    "\n",
    "    tr_loss, val_loss, tr_acc, val_acc = (0, 0, 0, 0)\n",
    "    for j in range(0, len(tr_target), batch_size):\n",
    "\n",
    "        # Validation conditions\n",
    "        if j == 0:\n",
    "            # Get accuracy and loss from validation data\n",
    "            vLoss, vAcc, vPred = sess.run([loss, accuracy, predicted], \n",
    "                                          feed_dict = {x: val_data,\n",
    "                                                       y_: val_target,\n",
    "                                                       training: False})\n",
    "                   \n",
    "            print(vPred)\n",
    "            \n",
    "            # Conditions for early stopping\n",
    "            if len(hist_loss) == hist_len:\n",
    "                hist_loss.pop(0)\n",
    "            hist_loss.append(vLoss)\n",
    "            curr_loss = np.mean(np.asarray(hist_loss)) \n",
    "            \n",
    "            print(\"Last loss {}. Curr loss {}.\".format(last_avg_loss, curr_loss))\n",
    "            \n",
    "            if last_avg_loss > curr_loss:\n",
    "                patience_cnt = 0\n",
    "                \n",
    "                # Save the model \n",
    "                if min_loss_seen == None or min_loss_seen > curr_loss:\n",
    "                    min_loss_seen = curr_loss\n",
    "                    saver.save(sess, './braincnn-19-model', global_step=epoch)\n",
    "                    saver.save(sess, './braincnn-19-model-final')\n",
    "            elif last_avg_loss == curr_loss:\n",
    "                patience_cnt = 0\n",
    "            else:\n",
    "                if epoch >= hist_len:\n",
    "                    patience_cnt += 1\n",
    "                \n",
    "            last_avg_loss = curr_loss\n",
    "                \n",
    "        # Training\n",
    "        rOpt, rLoss, rAcc = sess.run([opt, loss, accuracy], \n",
    "                                     feed_dict = {x: tr_data[j:j + batch_size],\n",
    "                                                  y_: tr_target[j:j + batch_size],\n",
    "                                                  training: True})\n",
    "\n",
    "        # Accumulate loss and accuracy stats to later calculate average of epoch\n",
    "        tr_loss += rLoss\n",
    "        val_loss += vLoss\n",
    "        tr_acc += rAcc\n",
    "        val_acc += vAcc\n",
    "\n",
    "        if j == 0:\n",
    "            print('Epoch {}. TrainL {}. ValL {}. Acc {}.'.format(epoch, rLoss, vLoss, vAcc))\n",
    "    \n",
    "    num_mini_batches = math.ceil(len(tr_target)/batch_size)\n",
    "    x_train.append(epoch)\n",
    "    y_train.append(tr_loss/num_mini_batches)\n",
    "    x_val.append(epoch)\n",
    "    y_val.append(val_loss/num_mini_batches)\n",
    "    x_tr_acc.append(epoch)\n",
    "    y_tr_acc.append(tr_acc/num_mini_batches)\n",
    "    x_val_acc.append(epoch)\n",
    "    y_val_acc.append(val_acc/num_mini_batches)\n",
    "    \n",
    "    # Plotting every 20 epochs\n",
    "    if epoch % 20 == 0:\n",
    "        plotting((x_train, y_train), (x_val, y_val), (x_tr_acc, y_tr_acc), (x_val_acc, y_val_acc))\n",
    "    \n",
    "    # Next epoch\n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final graph\n",
    "plotting((x_train, y_train), (x_val, y_val), (x_tr_acc, y_tr_acc), (x_val_acc, y_val_acc), final=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to restore model saved by early stopping\n",
    "with tf.Session() as sSess:\n",
    "    # Restore variables.\n",
    "    saver.restore(sSess, './braincnn-19-model-final')\n",
    "    print(\"Model restored.\")\n",
    "              \n",
    "    # Get accuracy and loss from validation data\n",
    "    sAcc, sPred = sSess.run([accuracy, predicted], \n",
    "                            feed_dict = {x: test_data,\n",
    "                                         y_: test_target,\n",
    "                                         training: False})\n",
    "    \n",
    "    print('Predicted classes {}'.format(sPred))\n",
    "    print('Testing accuracy {}'.format(sAcc))\n",
    "\n",
    "    # APOE e4 stats for testing data\n",
    "    e4_carrier_stats_post = {}\n",
    "    for k in range(0, len(sample_labels)):\n",
    "        e4_carrier_stats_post[k] = [0, 0]\n",
    "\n",
    "    # Get testing APOE e4 stats\n",
    "    for p in range(0, len(sPred)):\n",
    "        e4_carrier_stats_post[sPred[p]][1] += 1\n",
    "        if file_to_apoe[apoe_test_files[p]]:\n",
    "            e4_carrier_stats_post[sPred[p]][0] += 1\n",
    "\n",
    "    for cl_id, [quant, num_samples] in e4_carrier_stats_post.items():\n",
    "        if num_samples != 0:\n",
    "            print(\"Class {}. Pct APOE e4 carrier {}\".format(sample_labels[cl_id], \n",
    "                                                            quant/num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
